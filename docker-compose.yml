services:
  mosquitto:
    build:
      context: ./mosquitto
      dockerfile: Dockerfile
    ports:
      - "1883:1883"
      - "9001:9001"
    volumes:
      - ./mosquitto/config:/mosquitto/config
      - ./mosquitto/data:/mosquitto/data
      - ./mosquitto/log:/mosquitto/log

  simulator:
    build:
      context: ./simulator
      dockerfile: Dockerfile
    environment:
      - MQTT_BROKER=mosquitto
    depends_on:
      - mosquitto

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=verystrongpassword
      - SPARK_HOST=spark-master
      - SPARK_PORT=7077
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
      - MINIO_BUCKET=lake
    volumes:
      - spark-events:/tmp/spark-events  

  ingestor:
    build:
      context: ./ingestor
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      - MQTT_BROKER=mosquitto
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
    depends_on:
      - mosquitto


# --- Spark cluster -------------------------------------------------
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile
    hostname: spark-master
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_HOST=spark-master
      # --- (optional) security flags ‚Äì comment out if not needed ----
      # - SPARK_RPC_AUTHENTICATION_ENABLED=yes
      # - SPARK_RPC_AUTHENTICATION_SECRET=mysparksecret
      # - SPARK_RPC_ENCRYPTION_ENABLED=yes
      # - SPARK_SSL_ENABLED=yes
      - SPARK_METRICS_PROMETHEUS_ENABLED=true
    ports:
      - "7077:7077"   # cluster RPC
      - "8080:8080"   # master web-UI ‚Üí http://localhost:8080
    volumes:
      - spark-events:/tmp/spark-events   # shared event-logs

  spark-worker:
    build:
      context: ./spark
      dockerfile: Dockerfile    # `deploy` only works with Swarm/K8s; use `--scale` instead.
    hostname: spark-worker-{{.Task.Slot}}   # nice names if you scale
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G             # adjust to your host
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_METRICS_PROMETHEUS_ENABLED=true
    ports:
      - "8081:8081"   # worker web-UI ‚Üí http://localhost:8081
    depends_on:
      - spark-master
    volumes:
      - spark-events:/tmp/spark-events

  spark-history:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark-history
    # no SPARK_MODE here ‚îÄ we launch the class by hand
    command: >
      /opt/bitnami/spark/bin/spark-class
      org.apache.spark.deploy.history.HistoryServer
    environment:
      # Where the workers & master write their logs
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events
      - SPARK_METRICS_PROMETHEUS_ENABLED=true
    volumes:
      - spark-events:/tmp/spark-events   # same shared volume
    ports:
      - "18080:18080"    # UI ‚Üí http://localhost:18080
    depends_on:
      - spark-master
# -------------------------------------------------------------------

# ------------------------------------------------ MinIO object store
  minio:
    image: minio/minio:RELEASE.2025-04-22T22-12-26Z-cpuv1
    container_name: minio
    command: server /data --console-address ":9090"
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=minio123
    ports:
      - "9000:9000"   # S3 API  ‚Üí http://localhost:9000
      - "9090:9090"   # Web UI ‚Üí http://localhost:9090
    volumes:
      - minio-data:/data            # keeps objects between restarts

  # one-shot job that creates the bucket ‚Äúlake‚Äù if it‚Äôs missing
  # minio-init:
  #   image: minio/mc
  #   depends_on: [minio]
  #   entrypoint: >
  #     /bin/sh -c "
  #       until mc alias set local http://minio:9000 minio minio123; do sleep 1; done &&
  #       mc mb -p local/lake || true &&
  #       mc policy set public local/lake;
  #       exit 0"
# -------------------------------------------------------------------


  neo4j:
    image: neo4j:5.17.0
    ports:
      - "7474:7474"   # HTTP interface (UI)
      - "7687:7687"   # Bolt protocol
    environment:
      - NEO4J_AUTH=neo4j/verystrongpassword  # update credentials as required
      - NEO4J_PLUGINS=["apoc", "graph-data-science", "n10s"]
      # - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      # - apoc.import.file.enabled=true
    # volumes:
    #   - ./frontend/public/ontology.owl:/var/lib/neo4j/import/ontology.owl:ro

  # neo4j_importer:
  #   image: neo4j:latest
  #   depends_on:
  #     - neo4j
  #   volumes:
  #     - ./neo4j/init_ontology.sh:/init_ontology.sh:ro
  #   entrypoint: ["bash", "/init_ontology.sh"]

# -------------------------------------------------------------------
# üçã  Monitoring stack ‚Äì add after your existing services
# -------------------------------------------------------------------
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    container_name: cadvisor
    command:
      - --docker_only
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - "8089:8080"          # http://localhost:8089/metrics

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    ports:
      - "9091:9090"          # http://localhost:9091

  grafana:
    image: grafana/grafana:10.3.1
    container_name: grafana
    depends_on: [prometheus]
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3001:3000"          # http://localhost:3001
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/provisioning:/etc/grafana/provisioning # datasources & dashboards

# -------------------------------------------------------------------

volumes:
  spark-events: {}
  minio-data:   {}
  grafana-data: {}


